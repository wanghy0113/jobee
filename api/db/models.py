from peewee import (
    Model,
    CharField,
    TextField,
    DateTimeField,
    ForeignKeyField,
    BooleanField,
    IntegerField,
    SQL,
)
from playhouse.postgres_ext import PostgresqlExtDatabase, ArrayField
import datetime
import logging


logger = logging.getLogger('peewee')
logger.setLevel(logging.WARNING)
# Connect to a Postgres database.
db = PostgresqlExtDatabase(
    "jobee_dev", user="jobee_dev", password="319298", host="localhost", port=5432
)

# The following defines the database schema, all tables have an implicit id
# field generated by Peewee as incrementing integer.1


class BaseModel(Model):
    class Meta:
        database = db


class User(BaseModel):
    email = CharField(unique=True)
    password = CharField()
    created_at = DateTimeField(default=datetime.datetime.now)

    def to_dict(self):
        return {"id": self.get_id(), "email": self.email, "created_at": self.created_at}

    class Meta:
        db_table = "user"


class JobCrawlEntry(BaseModel):
    created_at = DateTimeField(default=datetime.datetime.now)
    last_run_at = DateTimeField(null=True)
    last_run_interval_days = IntegerField(null=True)

    platform = CharField()
    location = CharField()
    keywords = CharField()
    job_type = CharField(null=True)
    remote_ok = BooleanField(null=True)
    degree_required = CharField(null=True)
    experience_level = CharField(null=True)

    class Meta:
        db_table = "job_crawl_entry"


class DreamJob(BaseModel):
    # DreamJob is a table that stores the user's dream job descriptions.
    user = ForeignKeyField(User, backref="dream_jobs")
    raw_description = TextField()
    created_at = DateTimeField(default=datetime.datetime.now)
    last_matched_at = DateTimeField(null=True)

    def to_dict(self):
        return {
            "id": self.get_id(),
            "user_id": self.user.get_id(),
            "raw_description": self.raw_description,
            "created_at": self.created_at,
            "last_matched_at": self.last_matched_at,
        }

    class Meta:
        db_table = "dream_job"


class DreamJobCrawlEntry(BaseModel):
    # DreamJobCrawlEntry is a table that stores the relationship between DreamJob and JobCrawlEntry.
    # The design is that multiple dream jobs can share the same crawl entry given that the crawl params
    # are the same. This is to avoid duplicate crawl entries.
    dream_job = ForeignKeyField(DreamJob)
    job_crawl_entry = ForeignKeyField(JobCrawlEntry)

    class Meta:
        db_table = "dream_job_crawl_entry"


class JobCrawlResult(BaseModel):
    create_at = DateTimeField(default=datetime.datetime.now)
    updated_at = DateTimeField(default=datetime.datetime.now)
    job_crawl_entry = ForeignKeyField(JobCrawlEntry, backref="crawl_results")

    indeed_job_id = CharField(null=True, unique=True)
    indeed_job_url = CharField(null=True)
    google_job_id = CharField(null=True, unique=True)
    google_job_url = CharField(null=True)

    raw_content = TextField()
    title = CharField()
    skills = ArrayField(TextField, null=True)  # type: ignore
    salary = ArrayField(null=True)
    experience = CharField(null=True)
    salary = CharField(null=True)
    company = CharField()
    remote_ok = BooleanField(null=True)
    job_types = ArrayField(TextField, null=True)  # type: ignore
    benefits = ArrayField(TextField, null=True)  # type: ignore
    job_contents = ArrayField(TextField, null=True)  # type: ignore

    def to_dict(self, ignore_raw_content=False):
        res = {
            "id": self.get_id(),
            "job_crawl_entry_id": self.job_crawl_entry.get_id(),
            "indeed_job_id": self.indeed_job_id,
            "indeed_job_url": self.indeed_job_url,
            "google_job_id": self.google_job_id,
            "google_job_url": self.google_job_url,
            "title": self.title,
            "skills": self.skills,
            "salary": self.salary,
            "experience": self.experience,
            "company": self.company,
            "remote_ok": self.remote_ok,
            "job_types": self.job_types,
            "benefits": self.benefits,
            "job_contents": self.job_contents,
            "created_at": self.create_at,
            "updated_at": self.updated_at,
        }
        if not ignore_raw_content:
            res["raw_content"] = self.raw_content
            
        return res

    class Meta:
        db_table = "job_crawl_result"


class JobMatchResult(BaseModel):
    created_at = DateTimeField(default=datetime.datetime.now)
    updated_at = DateTimeField(default=datetime.datetime.now)
    dream_job = ForeignKeyField(DreamJob, backref="job_match_results")
    job_crawl_result = ForeignKeyField(JobCrawlResult, backref="job_match_results")

    matching_points = ArrayField(TextField, null=True)  # type: ignore
    warning_points = ArrayField(TextField, null=True)  # type: ignore

    def to_dict(self, populate_job_crawl_result=False):
        res = {
            "id": self.get_id(),
            "job_crawl_result_id": self.job_crawl_result.get_id(),
            "dream_job_id": self.dream_job.get_id(),
            "matching_points": self.matching_points,
            "warning_points": self.warning_points,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
        }
        if populate_job_crawl_result:
            res["job_crawl_result"] = self.job_crawl_result.to_dict(ignore_raw_content=True)
        return res

    class Meta:
        db_table = "job_match_result"
        constraints = [SQL("UNIQUE(dream_job_id, job_crawl_result_id)")]


def create_tables():
    with db:
        db.create_tables(
            [
                User,
                JobCrawlEntry,
                DreamJob,
                JobCrawlResult,
                JobMatchResult,
                DreamJobCrawlEntry,
            ]
        )
